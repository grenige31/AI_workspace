{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "afdf88fc-539f-4f5b-89af-5771cd7a5b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://mer.vin/2024/05/ragas-evaluate-rag-from-test-set/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9f0bbf95-8b70-4f86-bf22-aab3f0c10bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = os.environ.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f33eacda-fe81-4889-9ec6-f53499655227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings  #← OpenAIEmbeddings 가져오기\n",
    "import tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b0ef99e8-61f0-44d3-b681-bb7a2e1edff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings( #← OpenAIEmbeddings를 초기화\n",
    "    model=\"text-embedding-ada-002\" #← 모델명을 지정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7a10381c-a68c-4c3b-bdfa-8460a5eae3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 개수: 55\n"
     ]
    }
   ],
   "source": [
    "# FILE_PATH=\"./data/sample.pdf\"\n",
    "# CHROMA_DB_PATH=\"./vector_db/chroma/sample\"\n",
    "# TESTSET_FILE=\"pdf_testset.csv\"\n",
    "# EVAL_FILE=\"pdf_eval.csv\"\n",
    "\n",
    "FILE_PATH=\"./data/130292099630937500_KIFVIP2013-10.pdf\"\n",
    "TESTSET_FILE=\"pdf1_testset.csv\"\n",
    "EVAL_FILE=\"pdf1_eval.csv\"\n",
    "CHROMA_DB_PATH=\"./vector_db/chroma/130292099630937500_KIFVIP2013\"\n",
    "\n",
    "loader = PyPDFLoader(FILE_PATH) #← sample.pdf 로드\n",
    "\n",
    "# FILE_PATH=\"./data/llm.txt\"\n",
    "# TESTSET_FILE=\"txt_testset.csv\"\n",
    "# EVAL_FILE=\"txt_eval.csv\"\n",
    "# CHROMA_DB_PATH=\"./vector_db/chroma/llm\"\n",
    "# loader = TextLoader(FILE_PATH) #← llm.txt 로드\n",
    "\n",
    "documents = loader.load()\n",
    "print(f\"문서 개수: {len(documents)}\") #← 문서 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "106885f4-db31-4275-9533-490b8c0091d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a8a7dbfc9f47d8bc9216bc43c96149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tiktoken_len(text):\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = tokenizer.encode(text)\n",
    "    return len(tokens)\n",
    "    \n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=100,\n",
    "    length_function=tiktoken_len\n",
    ")    \n",
    "splits = text_splitter.split_documents(documents)\n",
    "\n",
    "generator_llm = ChatOpenAI(api_key=api_key,model=\"gpt-4o-mini\")\n",
    "critic_llm = ChatOpenAI(api_key=api_key,model=\"gpt-4o-mini\")\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ")\n",
    "\n",
    "testset = generator.generate_with_langchain_docs(documents, test_size=10, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})\n",
    "testset.to_pandas().to_csv(TESTSET_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "88cc53a4-58ea-4198-bede-7cfe0029805a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'contexts', 'ground_truth', 'evolution_type', 'metadata', 'episode_done', 'answer'],\n",
      "    num_rows: 10\n",
      "})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e2e054fe01453680217b450f25f166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No statements were generated from the answer.\n",
      "Failed to parse output. Returning None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_precision': 0.8000, 'faithfulness': 0.8241, 'answer_relevancy': 0.8448, 'context_recall': 0.7407}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset \n",
    "import pandas as pd\n",
    "import json \n",
    "import ast\n",
    "\n",
    "data = pd.read_csv(TESTSET_FILE)\n",
    "data['contexts'] = data['contexts'].apply(ast.literal_eval)  # convert string to list\n",
    "data['answer'] = data['ground_truth']\n",
    "\n",
    "json_data = data.to_json()\n",
    "dict_data = data.to_dict(orient='list')\n",
    "\n",
    "dataset = Dataset.from_dict(dict_data)\n",
    "\n",
    "amnesty_qa = dataset\n",
    "# amnesty_qa = load_dataset(\"explodinggradients/amnesty_qa\", \"english_v2\")\n",
    "print(amnesty_qa)\n",
    "\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "from ragas import evaluate\n",
    "\n",
    "result = evaluate(\n",
    "    amnesty_qa,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(result)\n",
    "df = result.to_pandas()\n",
    "df.to_csv(EVAL_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1939adf8-8cce-43ee-b1ee-c5d83b034ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ad053-e4d8-4795-83e9-15fee9d53365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
